# -*- coding: utf-8 -*-
"""siswa3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HglKywSbHz_-IVUaw1MK_UiAiePF3fcH

# MEMBUAT MODEL MESIN LEARNING UNTUK MEMPREDIKSI MODEL SISWA

Tujuan: Memprediksi nilai akhir siswa (G3) berdasarkan berbagai fitur demografis, sosial, dan pendidikan.

Student Performance Dataset

Sumber: UCI Machine Learning Repository

Format: CSV

Deskripsi: Data tentang performa siswa di Portugal. Berisi informasi seperti gender, absensi, waktu belajar, dan nilai akhir.

Link Unduh Langsung: https://archive.ics.uci.edu/ml/machine-learning-databases/00320/student.zip

## Data Preparation

### Memuat Dataset

Memuat data dari file CSV ke dalam Pandas DataFrame untuk mempermudah manipulasi dan analisis data.
Parameter:
sep=';': Menentukan pemisah kolom sebagai titik koma, karena dataset UCI Student Performance menggunakan format ini.
quotechar='"': Mengelola data yang berada di dalam tanda kutip ganda, sehingga teks dalam tanda kutip tidak terpotong.
Hasil: Data dari file CSV dimuat ke dalam variabel df sebagai Pandas DataFrame.
"""

import pandas as pd

# Mengunggah file CSV ke Google Colab
from google.colab import files
uploaded = files.upload()

# Menyebutkan nama file CSV yang telah diunggah
file_name = list(uploaded.keys())[0]

# Memuat dataset ke dalam DataFrame
df = pd.read_csv(file_name, sep=';', quotechar='"')

# Memeriksa struktur dataset
print("Info Dataset:")
print(df.info())
print("\nData Awal:")
print(df.head())

"""### Memeriksa missing value"""

# Mengecek apakah ada missing value
if df.isnull().sum().sum() == 0:
    print("Tidak ada missing value dalam dataset.")
else:
    # Penanganan missing value
    from sklearn.impute import SimpleImputer

    # Imputasi numerik
    numerical_imputer = SimpleImputer(strategy='mean')
    df[numerical_cols] = numerical_imputer.fit_transform(df[numerical_cols])

    # Imputasi kategorikal
    categorical_imputer = SimpleImputer(strategy='most_frequent')
    df[categorical_cols] = categorical_imputer.fit_transform(df[categorical_cols])

    print("Missing values setelah imputasi:")
    print(df.isnull().sum())

"""### Pengecekan outliers
Dilakukan untuk mendeteksi nilai yang berada jauh dari distribusi normal
"""

from scipy.stats import zscore

# Memilih kolom numerik
numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns

# Hitung Z-Score untuk semua kolom numerik
z_scores = df[numerical_cols].apply(zscore)

# Identifikasi baris yang bukan outliers
df_cleaned = df[(z_scores < 3).all(axis=1) & (z_scores > -3).all(axis=1)]

# Menampilkan 5 baris pertama data setelah penghapusan outliers
print("Data setelah penghapusan outliers:")
print(df_cleaned.head())

# Menampilkan ukuran data sebelum dan sesudah
print(f"\nJumlah data sebelum penghapusan: {df.shape[0]}")
print(f"Jumlah data setelah penghapusan: {df_cleaned.shape[0]}")

"""### Exploratory Data Analysis (EDA)

Mengeksplorasi data untuk memahami pola, distribusi, dan korelasi antar fitur.
"""

import seaborn as sns
import matplotlib.pyplot as plt

# Visualisasi distribusi nilai target (G3)
sns.histplot(df['G3'], kde=True, bins=10)
plt.title("Distribusi Nilai Akhir (G3)")
plt.xlabel("G3")
plt.ylabel("Frekuensi")
plt.show()

# Korelasi antar fitur numerik
numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns
plt.figure(figsize=(10, 8))
sns.heatmap(df[numerical_cols].corr(), annot=True, cmap="coolwarm")
plt.title("Korelasi Antar Fitur Numerik")
plt.show()

print(df.head())

"""### Feature Engineering

Proses memodifikasi atau membuat fitur baru untuk meningkatkan performa model.
"""

# Konversi kolom kategorikal menjadi kategori
categorical_cols = ['school', 'sex', 'address', 'famsize', 'Pstatus', 'Mjob', 'Fjob',
                    'reason', 'guardian', 'schoolsup', 'famsup', 'paid', 'activities',
                    'nursery', 'higher', 'internet', 'romantic']

for col in categorical_cols:
    df[col] = df[col].astype('category')

# One-hot encoding untuk kolom kategorikal
df = pd.get_dummies(df, drop_first=True)

print("\nData Setelah Feature Engineering:")
print(df.head())

"""### Data Normalization/Standardization

Menormalkan atau menstandarisasi fitur numerik agar memiliki skala yang seragam.
"""

from sklearn.preprocessing import StandardScaler

# Standarisasi kolom numerik
numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns
scaler = StandardScaler()
df[numerical_cols] = scaler.fit_transform(df[numerical_cols])

print("\nData Setelah Normalisasi:")
print(df.head())

"""### Data Splitting
Membagi dataset menjadi data latih (training) dan data uji (testing).
"""

from sklearn.model_selection import train_test_split

# Memisahkan fitur dan target
X = df.drop(columns=['G3'])  # G3 adalah target
y = df['G3']

# Membagi data latih dan uji
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("\nData Splitting:")
print(f"Training Data: {X_train.shape}")
print(f"Testing Data: {X_test.shape}")

"""## Modeling

### Membangun model machine learning  Random Forest
"""

from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score

# Membuat model Random Forest
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# Membuat prediksi
rf_pred = rf_model.predict(X_test)

# Evaluasi model
print("\nRandom Forest Model:")
print(f"Mean Squared Error (MSE): {mean_squared_error(y_test, rf_pred)}")
print(f"R² Score: {r2_score(y_test, rf_pred)}")

"""### Hyperparameter Tuning

Mencari parameter terbaik untuk model menggunakan teknik seperti GridSearchCV atau RandomizedSearchCV.
"""

from sklearn.model_selection import GridSearchCV

# Parameter yang akan di-tuning
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [10, 20, None],
    'min_samples_split': [2, 5, 10]
}

# GridSearchCV untuk Random Forest
grid_search = GridSearchCV(estimator=RandomForestRegressor(random_state=42), param_grid=param_grid, cv=5, n_jobs=-1, scoring='neg_mean_squared_error')
grid_search.fit(X_train, y_train)

# Menampilkan parameter terbaik
print("\nBest Parameters: ", grid_search.best_params_)

# Evaluasi model terbaik
best_rf_model = grid_search.best_estimator_
best_rf_pred = best_rf_model.predict(X_test)
print("\nTuned Random Forest Model:")
print(f"Mean Squared Error (MSE): {mean_squared_error(y_test, best_rf_pred)}")
print(f"R² Score: {r2_score(y_test, best_rf_pred)}")

"""## Evaluasi

Visualisasi performa model untuk membandingkan prediksi dengan nilai aktual.
"""

import matplotlib.pyplot as plt

# Visualisasi prediksi vs nilai aktual
plt.figure(figsize=(8, 6))
plt.scatter(y_test, best_rf_pred, alpha=0.7, label="Predicted vs Actual")
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'k--', lw=2, label="Perfect Prediction")
plt.title('Prediksi vs Nilai Aktual')
plt.xlabel('Nilai Aktual')
plt.ylabel('Prediksi')
plt.legend()
plt.show()

"""Hasil evaluasi model menunjukkan bahwa Tuned Random Forest Model memiliki performa yang cukup baik untuk memprediksi nilai akhir siswa berdasarkan data

### Feature Importance:

Identifikasi fitur mana yang paling berpengaruh pada prediksi model.
"""

import pandas as pd

# Mengambil feature importance dari model
feature_importances = pd.DataFrame({
    'Feature': X.columns,
    'Importance': best_rf_model.feature_importances_
}).sort_values(by='Importance', ascending=False)

print(feature_importances.head(10))

"""Fitur yang Paling Penting:

G2 memiliki skor 0.827512, yang berarti nilai ujian kedua adalah prediktor terpenting untuk nilai akhir siswa (G3).
Artinya, siswa yang memiliki nilai baik pada G2 cenderung juga mendapatkan nilai akhir yang baik.
Fitur Lainnya:

absences (0.036153) juga memberikan kontribusi, meskipun jauh lebih kecil dibandingkan G2.
Hal ini menunjukkan bahwa kehadiran siswa (absensi) sedikit memengaruhi hasil akhir.
Fitur dengan Pengaruh Kecil:

reason_other (0.005830) memiliki pengaruh sangat kecil. Artinya, alasan siswa memilih sekolah (kategori "other") hampir tidak memengaruhi nilai akhir siswa.
Fitur Sosial atau Keluarga:

freetime (0.007880) dan famrel (0.006603) menunjukkan bahwa waktu luang dan hubungan keluarga hanya memiliki pengaruh kecil terhadap nilai akhir siswa.
"""